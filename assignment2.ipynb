{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "assignment2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2db346a0be004d718dcb0dd042dcf6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07e3ddea2d3c44ee8c3252fcbdf7ecec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ea5db864dd14fe3a002fc98f61b5ae6",
              "IPY_MODEL_caa8a8d893d04d3b8516bea15b19d19d"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP-5mroS74zy",
        "colab_type": "text"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Состоит из **обязательной** и **бонусной** частей.\n",
        "\n",
        "Обязательная часть оценивается в **50 баллов** и выполняется до **16 декабря 09:00**.\n",
        "\n",
        "Бонусную часть можно делать, пока не придет необходимость получения оценки/зачета.\n",
        "\n",
        "Обязательная часть заключается в fine-tuning несложной нейросети (ResNet-18) на UIUC Sports Event Dataset (http://vision.stanford.edu/lijiali/event_dataset) и ее последующем ускорении с помощью фреймворка **NVIDIA TensorRT** (https://developer.nvidia.com/tensorrt)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyVd7CCs74z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okzIuMVe74z9",
        "colab_type": "text"
      },
      "source": [
        "**(5 баллов)** Скачайте датасет, распакуйте его в директорию `./event_img/`. В ней должны оказаться 8 директорий, соответствующих классам картинок. Загрузите датасет в torch и разбейте случайным образом на train и val."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYMePg-_8kSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "06621218-f0d4-4334-b89f-3584bdde249d"
      },
      "source": [
        "!wget http://vision.stanford.edu/lijiali/event_dataset/event_dataset.rar\n",
        "!unrar x event_dataset.rar"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-15 23:43:58--  http://vision.stanford.edu/lijiali/event_dataset/event_dataset.rar\n",
            "Resolving vision.stanford.edu (vision.stanford.edu)... 171.64.68.10\n",
            "Connecting to vision.stanford.edu (vision.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 495597858 (473M) [text/plain]\n",
            "Saving to: ‘event_dataset.rar’\n",
            "\n",
            "event_dataset.rar   100%[===================>] 472.64M  8.56MB/s    in 48s     \n",
            "\n",
            "2019-12-15 23:44:47 (9.76 MB/s) - ‘event_dataset.rar’ saved [495597858/495597858]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3o6TvPv74z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e12f3e4-cdd1-4971-d590-f8d3f89d3b41"
      },
      "source": [
        "event_dataset = torchvision.datasets.ImageFolder('event_img')\n",
        "assert isinstance(event_dataset, torch.utils.data.Dataset)\n",
        "\n",
        "dataset_length = len(event_dataset)\n",
        "print(f'Number of images: {dataset_length}')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images: 1579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFhPXNZh740F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_size = .4\n",
        "val_length = int(dataset_length * val_size)\n",
        "train_length = dataset_length - val_length\n",
        "\n",
        "train_data_raw, val_data_raw = torch.utils.data.random_split(event_dataset, [train_length, val_length])\n",
        "\n",
        "\n",
        "assert isinstance(train_data_raw, torch.utils.data.Dataset)\n",
        "assert isinstance(val_data_raw, torch.utils.data.Dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLDVfsE5740I",
        "colab_type": "text"
      },
      "source": [
        "**(10 баллов)** Нам нужны разные преобразования (transforms) для train и val. Напишите класс `ApplyTransform`, объект которого — тот же датасет, что подается в конструкторе, но с примененными преобразованиями.\n",
        "\n",
        "К `train_data_raw` нужно применить изменение размера до 256px (`min(height, width)`), извлечение региона 256x256 в центре, выбор в этом регионе случайного квадрата 224x224.\n",
        "\n",
        "К `test_data_raw` нужно применить изменение размера до 224px и извлечение региона 224x224 в центре."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akf69CbT740J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ApplyTransform(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, transform=None, target_transform=None):\n",
        "        self.data = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.__len__()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            X, y = self.data.__getitem__(index)\n",
        "            return self.transform(X), y\n",
        "        return self.data.__getitem__(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_oFU6su740L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagenet_normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(256),\n",
        "    torchvision.transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    imagenet_normalize\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    torchvision.transforms.Resize(224),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    imagenet_normalize\n",
        "])\n",
        "\n",
        "train_data = ApplyTransform(train_data_raw, train_transform)\n",
        "val_data = ApplyTransform(val_data_raw, val_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOefkuP8740O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=8)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6A95ao2740Q",
        "colab_type": "text"
      },
      "source": [
        "**(5 баллов)** Загрузите предобученную на ImageNet модель ResNet-18, адаптируйте ее под классификацию на 8 классов. Создайте подходящую функцию потерь и оптимизатор SGD с `momentum=0.9`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC3fF-Sr740Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 8\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7efgEzWV740S",
        "colab_type": "text"
      },
      "source": [
        "**(10 баллов)** Реализуйте обучение модели, а потом измерьте время инференса на val датасете (`batch_size=32`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2MQPj2i740S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "2db346a0be004d718dcb0dd042dcf6d4"
          ]
        },
        "outputId": "dc4f1426-f238-4553-99be-44a46d8aa1a3"
      },
      "source": [
        "import time\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    print(\"Epoch {}/{}\".format(epoch + 1, num_epochs), end='')\n",
        "    for X, y in train_loader:\n",
        "        print('.', end='')\n",
        "\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        model.train()\n",
        "\n",
        "        preds = model.forward(X)\n",
        "\n",
        "        loss_value = criterion(preds, y)\n",
        "        loss_value.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    print()\n",
        "\n",
        "t = []\n",
        "model.eval()\n",
        "for X, y in val_loader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    start = time.monotonic()\n",
        "    model.forward(X)\n",
        "    t.append(time.monotonic() - start)\n",
        "\n",
        "print(np.mean(t))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2db346a0be004d718dcb0dd042dcf6d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1 ..............................\n",
            "0.018155117600508676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCSuXmkz740U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# measure inference time\n",
        "# 0.018155117600508676"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsQU2ce9740V",
        "colab_type": "text"
      },
      "source": [
        "**(20 баллов)** Установите TensorRT и **torch2trt** (https://github.com/NVIDIA-AI-IOT/torch2trt). Оптимизируйте с помощью torch2trt обученную модель и снова измерьте время инференса.\n",
        "\n",
        "Попробуйте:\n",
        "* как режим fp32, так и fp16\n",
        "* не менее трех разных значений `batch_size`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8HnmXnN740W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch2trt import torch2trt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHHwK39v740X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyccnZ7q740Y",
        "colab_type": "text"
      },
      "source": [
        "### Бонусная часть (100 баллов)\n",
        "Нужно переписать функцию `torch2trt()`, чтобы она поддерживала **режим `int8`-инференса**.\n",
        "\n",
        "Сам TensorRT в режиме `int8` требует **калибровки**, которую нужно выполнять по train датасету. То есть нужно написать класс-калибратор (подкласс `tensorrt.IInt8EntropyCalibrator2`).\n",
        "\n",
        "За уточнением того, что надо сделать, и за помощью обращаться к:\n",
        "* https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#enable_int8_python\n",
        "* https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/python_api/index.html\n",
        "* примеру из TensorRT `samples/python/int8_caffe_mnist`\n",
        "* преподавателю через почтовый ящик курса или telegram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MZuCIGU740Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}